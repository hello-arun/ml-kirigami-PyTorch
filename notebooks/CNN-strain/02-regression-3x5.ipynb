{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We will only use here 3x5 grid instead of fine grid 30x80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZG149sjfrvS",
        "outputId": "501abe12-6c61-4773-a6ce-0edd91ba40ec"
      },
      "outputs": [],
      "source": [
        "# %tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib\n",
        "# matplotlib.use('TKAgg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "import os\n",
        "PROJECT_DIR = \"../../\"\n",
        "os.makedirs(\"./results/03x05-coarse-grid/\",exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAADhCAYAAAD8vH5jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAS0UlEQVR4nO3cQWyT9R/H8U+h2QGJCMKio0OplQEbZXEdDkxQDzpAnQgHx4WQSZohhJh48ORB4mHEk2GE2UiWYGA7mJiqbPNAmBGCjkLEyESbOXGrRDcBlWAYG7//4R8amw2ebn26/krfrxNPn9/zPF+efJZ80qd5PMYYIwAAAAvMyPUAAAAAt1FMAACANSgmAADAGhQTAABgDYoJAACwBsUEAABYw7GYNDQ0qLi4WBUVFRPuN8Zo9+7dCgQCCgaDOnv2rOtDApkix8h3ZBiFwrGYbNu2TV1dXXfc39nZqXg8rng8rkgkoh07drg6IOAGcox8R4ZRKByLydq1azVv3rw77o9Go9q6das8Ho9qamp09epVXbp0ydUhgUyRY+Q7MoxCkfFvTBKJhEpLS5PbPp9PiUQi09MC04ocI9+RYdwrvJmeYKI32ns8ngnXRiIRRSIRSdKFCxe0dOnSTC8PSJJ++eUXDQ8PT/n4dHNMhpEt05VhiRwjOzLN8G0ZFxOfz6eBgYHk9uDgoEpKSiZcGw6HFQ6HJUmhUEixWCzTywOS/p+nTKSbYzKMbJmuDEvkGNmRaYZvy/hRTl1dnQ4dOiRjjL7++mvNmTNHDz/8sBuzAdOGHCPfkWHcKxy/MdmyZYu6u7s1PDwsn8+nd955Rzdv3pQkNTY2asOGDero6FAgENCsWbPU2tqa9aGBySLHyHdkGIXCsZi0tbXddb/H49H+/ftdGwjIBnKMfEeGUSh48ysAALAGxQQAAFiDYgIAAKxBMQEAANagmAAAAGtQTAAAgDUoJgAAwBoUEwAAYA2KCQAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa1BMAACANSgmAADAGhQTAABgDYoJAACwBsUEAABYg2ICAACsQTEBAADWoJgAAABrUEwAAIA1KCYAAMAaFBMAAGANigkAALAGxQQAAFiDYgIAAKxBMQEAANagmAAAAGukVUy6urpUVlamQCCgpqamcfv/+usvvfTSS1q5cqXKy8vV2trq+qBAJsgw8h0ZRqFwLCZjY2PauXOnOjs71dvbq7a2NvX29qas2b9/v5YvX65z586pu7tbb775pkZGRrI2NDAZZBj5jgyjkDgWk56eHgUCAfn9fhUVFam+vl7RaDRljcfj0T///CNjjK5du6Z58+bJ6/VmbWhgMsgw8h0ZRiFxLCaJREKlpaXJbZ/Pp0QikbJm165d+uGHH1RSUqIVK1bo/fff14wZ/HwFdiDDyHdkGIXEMbXGmHGfeTyelO0vvvhClZWV+u233/Ttt99q165d+vvvv8cdF4lEFAqFFAqFNDQ0lMHYQPrIMPKdmxmWyDHs5lhMfD6fBgYGktuDg4MqKSlJWdPa2qpNmzbJ4/EoEAho8eLFunDhwrhzhcNhxWIxxWIxLViwwIXxAWdkGPnOzQxL5Bh2cywm1dXVisfj6u/v18jIiNrb21VXV5eyZtGiRTp27Jgk6ffff9ePP/4ov9+fnYmBSSLDyHdkGIXE8ZdRXq9Xzc3Nqq2t1djYmBoaGlReXq6WlhZJUmNjo95++21t27ZNK1askDFGe/fu1fz587M+PJAOMox8R4ZRSDxmooeX0yAUCikWi+Xi0rgH5SJPZBhuylWeyDHc4laW+Mk2AACwBsUEAABYg2ICAACsQTEBAADWoJgAAABrUEwAAIA1KCYAAMAaFBMAAGANigkAALAGxQQAAFiDYgIAAKxBMQEAANagmAAAAGtQTAAAgDUoJgAAwBoUEwAAYA2KCQAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa1BMAACANSgmAADAGhQTAABgDYoJAACwBsUEAABYg2ICAACsQTEBAADWoJgAAABrpFVMurq6VFZWpkAgoKampgnXdHd3q7KyUuXl5Xr66addHRLIFBlGviPDKBjGwejoqPH7/aavr8/cuHHDBINBc/78+ZQ1V65cMcuWLTMXL140xhjz+++/O53WVFVVOa4B0nW3PJFh5INcZNjpusBkuJUlx29Menp6FAgE5Pf7VVRUpPr6ekWj0ZQ1R44c0aZNm7Ro0SJJUnFxcXZaFDAFZBj5jgyjkDgWk0QiodLS0uS2z+dTIpFIWfPTTz/pypUreuaZZ1RVVaVDhw65PykwRWQY+Y4Mo5B4nRYYY8Z95vF4UrZHR0d15swZHTt2TP/++69Wr16tmpoaLVmyJGVdJBJRJBKRJA0NDWUyN5A2Mox852aGJXIMuzl+Y+Lz+TQwMJDcHhwcVElJybg169at03333af58+dr7dq1Onfu3LhzhcNhxWIxxWIxLViwwIXxAWdkGPnOzQxL5Bh2cywm1dXVisfj6u/v18jIiNrb21VXV5ey5uWXX9ZXX32l0dFRXb9+Xd98842WLVuWtaGBySDDyHdkGIXE8VGO1+tVc3OzamtrNTY2poaGBpWXl6ulpUWS1NjYqGXLlmndunUKBoOaMWOGtm/froqKiqwPD6SDDCPfkWEUEo+Z6OHlNAiFQorFYrm4NO5BucgTGYabcpUncgy3uJUl3vwKAACsQTEBAADWoJgAAABrUEwAAIA1KCYAAMAaFBMAAGANigkAALAGxQQAAFiDYgIAAKxBMQEAANagmAAAAGtQTAAAgDUoJgAAwBoUEwAAYA2KCQAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa1BMAACANSgmAADAGhQTAABgDYoJAACwBsUEAABYg2ICAACsQTEBAADWoJgAAABrUEwAAIA1KCYAAMAaaRWTrq4ulZWVKRAIqKmp6Y7rTp8+rZkzZ+rjjz92bUDADWQY+Y4Mo1A4FpOxsTHt3LlTnZ2d6u3tVVtbm3p7eydc99Zbb6m2tjYrgwJTRYaR78gwColjMenp6VEgEJDf71dRUZHq6+sVjUbHrdu3b582b96s4uLirAwKTBUZRr4jwygkjsUkkUiotLQ0ue3z+ZRIJMat+eSTT9TY2Oj+hECGyDDyHRlGIfE6LTDGjPvM4/GkbL/xxhvau3evZs6ceddzRSIRRSIRSdLQ0NBk5gSmjAwj37mZYYkcw26OxcTn82lgYCC5PTg4qJKSkpQ1sVhM9fX1kqTh4WF1dHTI6/Vq48aNKevC4bDC4bAkKRQKZTo7kBYyjHznZoYlcgy7ORaT6upqxeNx9ff3a+HChWpvb9eRI0dS1vT39yf/vW3bNr344osT/jEAuUCGke/IMAqJYzHxer1qbm5WbW2txsbG1NDQoPLycrW0tEgSzzNhPTKMfEeGUUg8ZqKHl9MgFAopFovl4tK4B+UiT2QYbspVnsgx3OJWlnjzKwAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa1BMAACANSgmAADAGhQTAABgDYoJAACwBsUEAABYg2ICAACsQTEBAADWoJgAAABrUEwAAIA1KCYAAMAaFBMAAGANigkAALAGxQQAAFiDYgIAAKxBMQEAANagmAAAAGtQTAAAgDUoJgAAwBoUEwAAYA2KCQAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa6RVTLq6ulRWVqZAIKCmpqZx+w8fPqxgMKhgMKg1a9bo3Llzrg8KZIIMI9+RYRQM42B0dNT4/X7T19dnbty4YYLBoDl//nzKmpMnT5rLly8bY4zp6Ogwq1atcjqtqaqqclwDpOtueSLDyAe5yLDTdYHJcCtLjt+Y9PT0KBAIyO/3q6ioSPX19YpGoylr1qxZo7lz50qSampqNDg4mJ0WBUwBGUa+I8MoJI7FJJFIqLS0NLnt8/mUSCTuuP7gwYNav369O9MBLiDDyHdkGIXE67TAGDPuM4/HM+Ha48eP6+DBgzpx4sSE+yORiCKRiCRpaGhoMnMCU0aGke/czLBEjmE3x29MfD6fBgYGktuDg4MqKSkZt+67777T9u3bFY1G9eCDD054rnA4rFgsplgspgULFmQwNpA+Mox852aGJXIMuzkWk+rqasXjcfX392tkZETt7e2qq6tLWfPrr79q06ZN+uijj7RkyZKsDQtMBRlGviPDKCSOj3K8Xq+am5tVW1ursbExNTQ0qLy8XC0tLZKkxsZG7dmzR3/++adef/315DGxWCy7kwNpIsPId2QYhcRjJnp4OQ1CoRB/NHBNLvJEhuGmXOWJHMMtbmWJN78CAABrUEwAAIA1KCYAAMAaFBMAAGANigkAALAGxQQAAFiDYgIAAKxBMQEAANagmAAAAGtQTAAAgDUoJgAAwBoUEwAAYA2KCQAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa1BMAACANSgmAADAGhQTAABgDYoJAACwBsUEAABYg2ICAACsQTEBAADWoJgAAABrUEwAAIA1KCYAAMAaFBMAAGANigkAALBGWsWkq6tLZWVlCgQCampqGrffGKPdu3crEAgoGAzq7Nmzrg8KZIIMI9+RYRQKx2IyNjamnTt3qrOzU729vWpra1Nvb2/Kms7OTsXjccXjcUUiEe3YsSNrAwOTRYaR78gwColjMenp6VEgEJDf71dRUZHq6+sVjUZT1kSjUW3dulUej0c1NTW6evWqLl26lLWhgckgw8h3ZBiFxLGYJBIJlZaWJrd9Pp8SicSk1wC5QoaR78gwConXaYExZtxnHo9n0mskKRKJKBKJSJK+//57hUKhtAedDkNDQ1qwYEGux0jBTOm5cOHCHfeR4dxipvRMV4YlcjwVts1k2zzS3TM8GY7FxOfzaWBgILk9ODiokpKSSa+RpHA4rHA4LEkKhUKKxWJTHjwbmCk9ts50J2Q4t5gpPdOVYYkcT4VtM9k2j3T3DE+G46Oc6upqxeNx9ff3a2RkRO3t7aqrq0tZU1dXp0OHDskYo6+//lpz5szRww8/7MqAQKbIMPIdGUYhcfzGxOv1qrm5WbW1tRobG1NDQ4PKy8vV0tIiSWpsbNSGDRvU0dGhQCCgWbNmqbW1NeuDA+kiw8h3ZBgFxeTIBx98kKtL3xEzpYeZcndNJ8yUHmbK/XXvhpmc2TaPMe7N5DFmgl9MAQAA5ACvpAcAANbISjHJ5NXJTsdma6bDhw8rGAwqGAxqzZo1OnfuXHLfo48+qhUrVqiystK1Xx07zdPd3a05c+aosrJSlZWV2rNnT9rHZmum9957LzlPRUWFZs6cqcuXL0vKzj2SpIaGBhUXF6uiomLC/dnKEhl2ZyZyTIYnMxMZTu+893yGXXkg9B+jo6PG7/ebvr4+c+PGDRMMBs358+dT1hw9etSsW7fO3Lp1y5w6dcqsWrUq7WOzNdPJkyfN5cuXjTHGdHR0JGcyxphHHnnEDA0NZTzHZOY5fvy4eeGFF6Z0bLZm+q9PP/3UPPvss8ltt+/RbV9++aU5c+aMKS8vn3B/NrJEht2biRyT4cnMRIbJsDHGuP6NSSavTk7n2GzNtGbNGs2dO1eSVFNTo8HBwYyvm8k82TjWzfO2tbVpy5YtGV/Xydq1azVv3rw77s9GlsiwezNl41g3zzsdOSbD6c9EhsmwlIVHOZm8Ojlbr1Se7HkPHjyo9evXJ7c9Ho+ef/55VVVVJd+WOB3znDp1SitXrtT69et1/vz5Kf1f3J5Jkq5fv66uri5t3rw5+Znb9yhd2cgSGXZ3JnJ8d2R4YmTY+bz3aoYd32MyWSaDVyenc2y2Zrrt+PHjOnjwoE6cOJH87OTJkyopKdEff/yh5557TkuXLtXatWuzOs8TTzyhixcvavbs2ero6NDGjRsVj8etuEefffaZnnrqqZQG7fY9Slc2skSG3ZuJHDsjw+OR4fTOe69m2PVvTDJ5dfJkXqns9kyS9N1332n79u2KRqN68MEHk5/fXltcXKxXXnlFPT09WZ/n/vvv1+zZsyVJGzZs0M2bNzU8PJzzeyRJ7e3t4746dPsepSsbWSLD7s1Ejp2R4VRkmAy7/uPXmzdvmsWLF5uff/45+WOX77//PmXN559/nvJDmerq6rSPzdZMFy9eNI899pg5efJkyufXrl0zf//9d/Lfq1evNp2dnVmf59KlS+bWrVvGGGO++eYbU1paam7dupXTe2SMMVevXjVz5841165dS36WjXv0X/39/Xf80VU2skSG3ZuJHP8fGSbDbs5kzL2d4ay8+fXo0aPm8ccfN36/37z77rvGGGMOHDhgDhw4YIwx5tatW+b11183fr/fVFRUmNOnT9/12OmY6bXXXjMPPPCAWblypVm5cqWpqqoyxhjT19dngsGgCQaDZvny5a7N5DTPvn37zPLly00wGDRPPvlkyh9qru6RMca0traaV199NeW4bN0jY4ypr683Dz30kPF6vWbhwoXmww8/nJYskWF3ZiLHZHgyM5Hh9GYy5t7OMG9+BQAA1uDNrwAAwBoUEwAAYA2KCQAAsAbFBAAAWINiAgAArEExAQAA1qCYAAAAa1BMAACANf4HhOxyNGFey/IAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 648x252 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 3)\n",
        "fig.set_facecolor(\"White\")\n",
        "fig.set_size_inches(9, 3.5)\n",
        "\n",
        "# fig.tight_layout(pad=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reset_fig():\n",
        "    for ax in axes:\n",
        "        ax.cla()\n",
        "        ax.set_xlim([0, 1])\n",
        "        ax.set_ylim([0, 1])\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"Target\")\n",
        "        # ratio = 1.0\n",
        "        # x_left, x_right = ax.get_xlim()\n",
        "        # y_low, y_high = ax.get_ylim()\n",
        "        # ax.set_aspect(\"equal\")\n",
        "    axes[0].set_title(\"Train\")\n",
        "    axes[1].set_title(\"Validation\")\n",
        "    axes[2].set_title(\"Test\")\n",
        "    fig.suptitle(\"Hello\")\n",
        "    fig.subplots_adjust(\n",
        "        left=0.075,\n",
        "        right=0.975,\n",
        "        top=0.85,\n",
        "        bottom=0.15,\n",
        "        wspace=0.3, hspace=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S70acHFspzh"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dGaSVmR3gI56"
      },
      "outputs": [],
      "source": [
        "alldata_15G = np.loadtxt(f'{PROJECT_DIR}/raw/alldata_15G.dat',dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOarrgEtfVi"
      },
      "source": [
        "## Split Train, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC46CrU4tlWM",
        "outputId": "137e0969-375e-48cd-a0aa-8c4a3df1abcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32 torch.float32\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(23833, 2979, 2979)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FIG_NO=0\n",
        "FEATURES = 15\n",
        "STRAIN, TOUGHNESS, STRESS = -3, -2, 1\n",
        "prop=STRAIN\n",
        "max_prop = np.max(alldata_15G[:, STRAIN])\n",
        "\n",
        "inputs = torch.from_numpy(alldata_15G[:, 0:FEATURES]).float().reshape(-1,1,3,5)\n",
        "targets = torch.from_numpy(alldata_15G[:, prop]/max_prop).float().reshape(-1,1)\n",
        "print(targets.dtype,inputs.dtype)\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [23833, 2979, 2979])\n",
        "len(train_ds), len(val_ds), len(test_ds)\n",
        "# Shuffle the data although not needed as it is already suffled\n",
        "# np.random.shuffle(alldata_15G)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataLoader and Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 200\n",
        "train_dl = DataLoader(train_ds,batch_size,shuffle=True,pin_memory=True)\n",
        "val_dl = DataLoader(val_ds,batch_size,pin_memory=True)\n",
        "test_dl = DataLoader(test_ds,batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuxttlngu3Kh"
      },
      "source": [
        "## Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KirigamiModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=\"same\"),\n",
        "            nn.ReLU(),              \n",
        "            # nn.MaxPool2d(2, 2),  # output: 16 x 3 x 5\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(2, 2),  # output: 32 x 3 x 5\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(2, 2),  # output: 64 x 3 x 5\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(960,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,1),\n",
        "        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, targets = batch\n",
        "        preds = self(images)                  # Generate predictions\n",
        "        loss = F.mse_loss(preds, targets)  # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, targets = batch\n",
        "        preds = self(images)                    # Generate predictions\n",
        "        loss = F.mse_loss(preds, targets)       # Calculate loss\n",
        "        # acc = accuracy(preds, targets)        # Calculate accuracy\n",
        "        return {'val_loss': loss.detach()}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        # batch_accs = [x['val_acc'] for x in outputs]\n",
        "        # epoch_acc = torch.stack(batch_accs).mean()    # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss']))\n",
        "\n",
        "model = KirigamiModel()\n",
        "# trial_input = torch.rand((4,1,30,80))\n",
        "# print(trial_input.dtype)\n",
        "# model(trial_input).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device,non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)\n",
        "model = to_device(model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            imgs, targets = batch\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "history=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 0.0003, val_loss: 0.0005\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0005\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0005\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0005\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0007\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0001, val_loss: 0.0007\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0002, val_loss: 0.0006\n",
            "Epoch [0], train_loss: 0.0001, val_loss: 0.0006\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epochs):\n",
        "    history = fit(1, lr, model, train_dl, val_dl, opt_func)\n",
        "    reset_fig()\n",
        "\n",
        "    for imgs,targets in train_dl:\n",
        "        axes[0].plot(model(imgs).detach().cpu(),targets.cpu(),\"k.\")\n",
        "        axes[0].plot([0,1],[0,1],\"r--\")\n",
        "\n",
        "    for imgs,targets in val_dl:\n",
        "        axes[1].plot(model(imgs).detach().cpu(),targets.cpu(),\"k.\")\n",
        "        axes[1].plot([0,1],[0,1],\"r--\")\n",
        "\n",
        "\n",
        "    for imgs,targets in test_dl:\n",
        "        axes[2].plot(model(imgs).detach().cpu(),targets.cpu(),\"k.\")\n",
        "        axes[2].plot([0,1],[0,1],\"r--\")\n",
        "    fig.suptitle(f\"Epoch: {FIG_NO:02d}\")\n",
        "    fig.savefig(F\"./results/03x05-coarse-grid/epoch-{FIG_NO:02d}.png\",dpi=300)\n",
        "    FIG_NO+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"./models/regression\",exist_ok=True)\n",
        "torch.save(model.state_dict(), './models/regression/f16-f32-f64-h64-3x5-coarse-grid.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9S70acHFspzh"
      ],
      "name": "CNN-regression.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit ('pytorch-1.12.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "4bf133e68ea69dc128944cff77d5d532fddfd436c4ee2509df098c607a2dfdac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
